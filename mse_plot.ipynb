{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cad3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial import distance\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796a8be",
   "metadata": {},
   "source": [
    "## USING PREVIOUS DATA\n",
    "\n",
    "We want to be able to save thing \n",
    "\n",
    "IF PICKLED = True then we will previously simulated data using the pickle packge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea10322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f16178",
   "metadata": {},
   "source": [
    "### Simulation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a944aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dp_bounds_threaded import dp_bounds\n",
    "# from modules.dp_bounds import dp_bounds\n",
    "\n",
    "from modules.Bhattacharyya_bounds import Bhattacharyya_bounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de25f9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100,  153,  235,  361,  553,  849, 1303, 2000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sizes = np.logspace(2, 3.3011, 8 , endpoint = True, dtype = int)\n",
    "\n",
    "sample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52b7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sep = 2.56\n",
    "# Set the mean and covariance matrix for each Gaussian distribution\n",
    "\n",
    "mean1 = [0, 0, 0 , 0 , 0, 0, 0 , 0]\n",
    "# covariance1 = np.ones((3,3))\n",
    "covariance1 = np.identity(8)\n",
    "# covariance1 = [[1, 0, 0],  [0, 1, 0], [0, 0, 0]\n",
    "\n",
    "mean2 = [mean_sep, 0, 0 , 0, 0, 0,0, 0 ]\n",
    "# mean2 = [math.sqrt(1/2), math.sqrt(1/2), 0]\n",
    "\n",
    "# covariance2 = np.ones((3,3))\n",
    "covariance2= np.identity(8)\n",
    "\n",
    "\n",
    "MC_num = 400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8638125",
   "metadata": {},
   "source": [
    "##### Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bd974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with  100  in  8.926054000854492\n",
      "done with  153  in  12.706019878387451\n",
      "done with  235  in  19.690170526504517\n",
      "done with  361  in  35.389612674713135\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dp_lst = []\n",
    "\n",
    "Bha_lst = []\n",
    "\n",
    "if PICKLED: ## We just skip all the data creation if we are using save data. \n",
    "    print(\"USING PREVIOUS DATA NOT SIMULATING DATA \")\n",
    "else:\n",
    "    for i in sample_sizes:\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        n0, n1 = i, i\n",
    "        params1  = [mean1, covariance1, n0]\n",
    "        params2  = [mean2, covariance2, n1]\n",
    "\n",
    "        dp_class = dp_bounds('mv_normal', params1, params2, MC_num, threads = 4, handle_errors= 'worst')\n",
    "    #     dp_class = dp_bounds('mv_normal', params1, params2, MC_num, handle_errors= 'worst')\n",
    "\n",
    "        Bha_class = Bhattacharyya_bounds('mv_normal', params1, params2, MC_num)\n",
    "\n",
    "        dp_lst.append(dp_class)\n",
    "        Bha_lst.append(Bha_class)\n",
    "        end = time.time()\n",
    "        print(\"done with \", i, \" in \",  end -start )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05465bc9",
   "metadata": {},
   "source": [
    "##### Pickling\n",
    "This is where the data either gets save or loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eac825",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sim_data/mse_data_v1.pkl'\n",
    "\n",
    "\n",
    "if PICKLED  == False:\n",
    "    objects_to_save = [dp_lst, Bha_lst]\n",
    "\n",
    "\n",
    "    with open(file_path, 'wb') as file:\n",
    "        # Use pickle.dump to serialize and write the list of objects to the file\n",
    "        pickle.dump(objects_to_save, file)\n",
    "    print(f'Objects saved to {file_path}')\n",
    "    \n",
    "\n",
    "elif PICKLED == True:\n",
    "    \n",
    "\n",
    "    # Open the file in binary read mode\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Use pickle.load to deserialize and load the list of objects from the file\n",
    "        loaded_objects = pickle.load(file)\n",
    "\n",
    "    print('Loaded object successfully')\n",
    "    \n",
    "    dp_lst, Bha_lst = loaded_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dace89",
   "metadata": {},
   "source": [
    "## Using simulated data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24098299",
   "metadata": {},
   "source": [
    "### Calculate BER and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4732a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.001\n",
    "x = np.arange(-5, 5 + dx, dx)\n",
    "\n",
    "f0 = np.exp(-0.5 * (x - 0)**2) / np.sqrt(2 * np.pi)\n",
    "f1 = np.exp(-0.5 * (x - mean_sep)**2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "fmin = np.minimum(f0, f1)\n",
    "\n",
    "BER = 0.5 * np.sum(fmin * dx)\n",
    "\n",
    "print(\"BER 2d:\", BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02443c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BER_lst = np.ones(MC_num) * BER\n",
    "\n",
    "\n",
    "def mse(l1, l2):## numpy lists\n",
    "    return ((l1 - l2)**2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_mse_DP = []\n",
    "upper_mse_DP =[]\n",
    "\n",
    "lower_mse_Bha = []\n",
    "upper_mse_Bha =[]\n",
    "\n",
    "\n",
    "for obj in dp_lst:\n",
    "    l_mse = mse(BER_lst, obj.get_bounds()[0]) \n",
    "    lower_mse_DP.append(l_mse)\n",
    "    \n",
    "    u_mse = mse(BER_lst, obj.get_bounds()[1])\n",
    "    upper_mse_DP.append(u_mse)       \n",
    "\n",
    "    \n",
    "for obj in Bha_lst:\n",
    "    l_mse = mse(BER_lst, obj.get_bounds()[0]) \n",
    "    lower_mse_Bha.append(l_mse)\n",
    "    \n",
    "    u_mse = mse(BER_lst, obj.get_bounds()[1])\n",
    "    upper_mse_Bha.append(u_mse)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c967a",
   "metadata": {},
   "source": [
    "### Theoretical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374acbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.Bhattacharyya import Bhattacharyya_bounds as Bhattacharyya_bounds_calc\n",
    "\n",
    "mean1 = np.array(mean1)\n",
    "mean2 = np.array(mean2)\n",
    "\n",
    "theory_bha = Bhattacharyya_bounds_calc([mean1, covariance1], [mean2, covariance2])\n",
    "\n",
    "\n",
    "\n",
    "MATLAB = [.0792, 0.1459]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad364a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = len(sample_sizes)\n",
    "\n",
    "## theoretical MSE\n",
    "bha_theoretical_l= np.ones(cases) * ((theory_bha[0]- BER)**2)\n",
    "bha_theoretical_u= np.ones(cases) *( (theory_bha[1]-BER)**2)\n",
    "\n",
    "\n",
    "dp_theoretical_l= np.ones(cases) * ((MATLAB[0]- BER)**2)\n",
    "dp_theoretical_u= np.ones(cases) * ((MATLAB[1]- BER)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbbfab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb9f9b7",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs =17\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set_xscale('log', base=10)\n",
    "ax.set_yscale('log', base=10)\n",
    "\n",
    "ax.plot(sample_sizes, lower_mse_DP,'r', label='Lower Bound Dp')\n",
    "ax.plot(sample_sizes, lower_mse_Bha,'b', label='Lower Bound Bha')\n",
    "\n",
    "ax.plot(sample_sizes, dp_theoretical_l,  'r:', label='Theoretical Lower Bound Dp')\n",
    "\n",
    "ax.plot(sample_sizes, bha_theoretical_l,  'b:', label='Theoretical Lower Bound Bha')\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Sample Size (Log Scale)  \", fontsize = fs)\n",
    "ax.set_ylabel(\"MSE (Log Scale) \", fontsize=fs)\n",
    "ax.set_title(\"MSE of Lower Bounds for 8 Dimensional Data Set\", fontsize = fs +4)\n",
    "ax.legend()\n",
    "# plt.savefig(\"log_test.png\",facecolor=(1,1,1,1))\n",
    "# ax.set_xticks(sample_sizes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs =17\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set_xscale('log', base=10)\n",
    "ax.set_yscale('log', base=10)\n",
    "\n",
    "ax.plot(sample_sizes, upper_mse_DP, 'r', label='Upper Bound Dp')\n",
    "ax.plot(sample_sizes, upper_mse_Bha,'b', label='UPper Bound Bha')\n",
    "\n",
    "ax.plot(sample_sizes, bha_theoretical_u,  'b:', label='Lower Bound Bha Theory')\n",
    "ax.plot(sample_sizes, dp_theoretical_u,  'r:', label='Theoretical Upper Bound Dp')\n",
    "\n",
    "ax.set_xlabel(\"Sample Size (Log Scale)  \", fontsize = fs)\n",
    "ax.set_ylabel(\"MSE (Log Scale) \", fontsize=fs)\n",
    "ax.set_title(\"MSE of Upper Bounds for 8 Dimensional Data Set\", fontsize = fs +4)\n",
    "ax.legend()\n",
    "# plt.savefig(\"log_test.png\",facecolor=(1,1,1,1))\n",
    "# ax.set_xticks(sample_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fs = 17\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10,8))\n",
    "\n",
    "# Plot for Upper Bounds\n",
    "axes[0].set_xscale('log', base=10)\n",
    "axes[0].set_yscale('log', base=10)\n",
    "axes[0].plot(sample_sizes, upper_mse_DP, label='Upper Bound Dp')\n",
    "axes[0].plot(sample_sizes, upper_mse_Bha, label='Upper Bound Bha')\n",
    "axes[0].set_xlabel(\"Sample Size (Log Scale)\", fontsize=fs)\n",
    "axes[0].set_ylabel(\"MSE (Log Scale)\", fontsize=fs)\n",
    "axes[0].set_title(\"MSE of Upper Bounds for 8 Dimensional Data Set\", fontsize=fs + 4)\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot for Lower Bounds\n",
    "axes[1].set_xscale('log', base=10)\n",
    "axes[1].set_yscale('log', base=10)\n",
    "axes[1].plot(sample_sizes, lower_mse_DP, label='Lower Bound Dp')\n",
    "axes[1].plot(sample_sizes, lower_mse_Bha, label='Lower Bound Bha')\n",
    "axes[1].set_xlabel(\"Sample Size (Log Scale)\", fontsize=fs)\n",
    "axes[1].set_ylabel(\"MSE (Log Scale)\", fontsize=fs)\n",
    "axes[1].set_title(\"MSE of Lower Bounds for 8 Dimensional Data Set\", fontsize=fs + 4)\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Both_bounds.png\",facecolor=(1,1,1,1))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c884046",
   "metadata": {},
   "outputs": [],
   "source": [
    "validity_dp_l = np.zeros(len(sample_sizes))\n",
    "validity_dp_u = np.zeros(len(sample_sizes))\n",
    "\n",
    "validity_Bha_l = np.zeros(len(sample_sizes))\n",
    "validity_Bha_u =  np.zeros(len(sample_sizes))\n",
    "\n",
    "for i in range(len(sample_sizes)):\n",
    "    Bha_l, Bha_u = Bha_lst[i].get_bounds()\n",
    "    dp_l, dp_u = dp_lst[i].get_bounds()\n",
    "    for j in range(MC_num):\n",
    "        if Bha_l[j] < BER:\n",
    "            validity_Bha_l[i] += 1\n",
    "        if Bha_u[j] > BER:\n",
    "            validity_Bha_u[i] += 1\n",
    "    \n",
    "        if dp_l[j] < BER:\n",
    "            validity_dp_l[i] += 1\n",
    "        if dp_u[j] > BER:\n",
    "            validity_dp_u[i] += 1\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validity_dp_l,  validity_dp_u, validity_Bha_l, validity_Bha_u )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34484dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs =17\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "\n",
    "ax = axes[0]\n",
    "\n",
    "ax.set_xscale('log', base=10)\n",
    "# ax.set_yscale('log', base=10)\n",
    "\n",
    "ax.plot(sample_sizes, validity_dp_l/ MC_num, 'b',  label='Lower Dp Validity ')\n",
    "ax.plot(sample_sizes, validity_dp_u/ MC_num, 'r', label='UPper Dp Validity ')\n",
    "\n",
    "ax.plot(sample_sizes, validity_Bha_l/ MC_num,'g', label='Lower Bha Validity ')\n",
    "ax.plot(sample_sizes, validity_Bha_u/ MC_num, 'orange', label='Upper Bha Validity ')\n",
    "\n",
    "# ax.set_xticks(sample_sizes)\n",
    "\n",
    "ax.set_xlabel(\"Sample Size (Log Scale)  \", fontsize = fs)\n",
    "ax.set_ylabel(\"Proportion the bound was valid \", fontsize=fs)\n",
    "ax.set_title(\"Validity Proportions\" , fontsize = fs +4)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax = axes[1]\n",
    "\n",
    "ax.set_xscale('log', base=10)\n",
    "# ax.set_yscale('log', base=10)\n",
    "\n",
    "# ax.plot(sample_sizes, validity_dp_l/ MC_num, 'b',  label='Lower Dp Validity ')\n",
    "ax.plot(sample_sizes, validity_dp_u/ MC_num, 'r', label='UPper Dp Validity ')\n",
    "\n",
    "ax.plot(sample_sizes, validity_Bha_l/ MC_num,'g', label='Lower Bha Validity ')\n",
    "ax.plot(sample_sizes, validity_Bha_u/ MC_num, 'orange', label='Upper Bha Validity ')\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Sample Size (Log Scale)  \", fontsize = fs)\n",
    "ax.set_ylabel(\"Proportion the bound was valid \", fontsize=fs)\n",
    "ax.set_title(\"Validity Proportions\" , fontsize = fs +4)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "# plt.savefig(\"proportions.png\",facecolor=(1,1,1,1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
